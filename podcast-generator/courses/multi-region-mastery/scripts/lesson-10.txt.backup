Episodes 3 and 6 taught you Aurora Global Database and DynamoDB Global Tables. Aurora replicates with 45-85ms lag. DynamoDB replicates in 1-3 seconds. Both work great in demos.

Then production happens. User updates their email in US-EAST-1. Immediately refreshes the page, gets routed to US-WEST-2. Sees their old email. Bug report: "I updated my email but the change didn't save."

What happened? Eventual consistency. The update hit US-EAST-1 DynamoDB. It hasn't replicated to US-WEST-2 yet. The user's read hit US-WEST-2 before replication finished. They saw stale data.

Today you're learning data consistency models in multi-region architectures. Not the theory. The production reality with user-facing consequences.

By the end of this lesson, you'll understand the CAP theorem - why you cannot have Consistency, Availability, and Partition tolerance all three. How Aurora chooses CP and DynamoDB chooses AP. The consistency models: strong, eventual, causal, read-your-writes. Real examples where eventual consistency caused bugs and how to fix them. And how to design applications for eventual consistency without breaking user trust.

Let's start with CAP theorem, the fundamental trade-off that governs all distributed systems.

CAP stands for Consistency, Availability, Partition tolerance. Pick two. You cannot have all three.

Consistency: All nodes see the same data at the same time. When you write to US-EAST-1, you immediately read that value from US-WEST-2.

Availability: Every request receives a response, even if some nodes are down.

Partition tolerance: The system continues operating despite network failures between nodes.

In single-region single-AZ, you can have CA. All nodes on the same network, no partitions. But that's not fault-tolerant.

In multi-region, network partitions are inevitable. Internet connections fail. Cross-region links have issues. You must handle partitions. So partition tolerance is mandatory. You're choosing between CP and AP.

CP: Consistency plus partition tolerance. During partition, reject writes to maintain consistency. Aurora Global Database is CP.

AP: Availability plus partition tolerance. During partition, accept writes in all regions, resolve conflicts later. DynamoDB Global Tables is AP.

Aurora's CP model works like this. Primary region accepts writes. Secondary regions read-only. During partition between regions, secondary cannot reach primary, it refuses to accept writes. Consistency is guaranteed - all reads see the same data. But availability suffers - you can't write to secondary during partition.

During normal operation, reads to secondary might see slightly stale data due to 45-85ms replication lag. But Aurora provides "read your writes" consistency if you read from primary.

DynamoDB's AP model is different. All regions accept writes. During partition between US-EAST-1 and US-WEST-2, both keep accepting writes. Later when partition heals, conflicts are resolved via last-writer-wins. Availability is maintained - writes always succeed. But consistency is eventual - reads might see stale data until replication catches up.

Which is better? Depends on your use case. Financial transactions, inventory management, order processing - you need consistency. Use Aurora with CP. User preferences, shopping carts, session data - you can tolerate eventual consistency. Use DynamoDB with AP.

Now consistency models from strongest to weakest.

Linearizability or strong consistency: Most strict. Reads always see the latest write. Acts like a single copy. Aurora primary provides this. But only within one region. Cross-region is eventually consistent.

Sequential consistency: All operations appear in some sequential order. Different nodes might see operations in different orders, but each node's view is consistent. Rarely implemented in production systems.

Causal consistency: If operation A causes operation B, all nodes see A before B. But unrelated operations might appear in different orders. DynamoDB doesn't provide this by default.

Eventual consistency: All nodes will eventually see the same data, given enough time without new writes. No guarantees on when. DynamoDB Global Tables provides this.

Read-your-writes consistency: After you write, your subsequent reads see your write. But other users might not see it yet. DynamoDB provides this if you read from the same region you wrote to.

Monotonic reads: If you've seen a particular value, you never see older values in future reads. DynamoDB doesn't guarantee this across regions. User reads from US-EAST-1, sees updated email. Next read from US-WEST-2, sees old email. Not monotonic.

The email update problem from the opening. User writes to US-EAST-1. DynamoDB accepts, replication starts. User refreshes immediately, gets routed to US-WEST-2 by Route53 latency-based routing. US-WEST-2 hasn't received replication yet. User sees old value.

This is not a bug in DynamoDB. This is eventual consistency working as designed. The bug is in your application assuming strong consistency.

Fixes: Make writes sticky to region. After user writes to US-EAST-1, keep them on US-EAST-1 for next few requests. Use session cookies to track write region. Or show "Your changes are being saved" message during replication period.

Real production example: Social media app, DynamoDB Global Tables. User posts comment in US-WEST-2. Post succeeds. They refresh immediately, Route53 sends them to US-EAST-1 for lower latency. The comment isn't visible yet. User thinks it failed, posts again. Now there are duplicate comments. Support tickets pile up.

Fix: After post, redirect user to permalink that specifies the region. Use route like /posts/123?region=us-west-2. Application reads from that region for next thirty seconds. By then replication has caught up. User sees their post immediately. After thirty seconds, switch back to latency-based routing.

Another pattern: Version numbers. Every item has a version field. When user writes, increment version. Show UI loading state until version propagates to all regions. Query all regions, wait until version matches everywhere. Then show success.

This trades latency for perceived consistency. User waits three seconds after clicking save. But they see immediate feedback that save is processing. Better than appearing successful then showing stale data.

Aurora consistency patterns are different because Aurora is CP. Primary accepts writes. Secondary read-only. If you route writes to primary and reads to secondary, you get read-after-write consistency problems.

User writes to primary in US-EAST-1. Immediately reads from secondary in same region. Secondary is 45-85ms behind. User sees stale data even though both requests hit same region.

Fix: Read from primary for critical reads where stale data causes user confusion. Read from secondary for less critical reads where eventual consistency is fine. Or use Aurora's reader endpoint with session-level read consistency.

But don't read everything from primary. That defeats the purpose of having read replicas. Be selective. Account settings page - read from primary. Product catalog - read from secondary, eventual consistency is fine.

Conflict resolution in DynamoDB revisiting Episode 6. When two regions write to same item simultaneously, last-writer-wins based on timestamp. But clocks drift. AWS NTP keeps clocks synchronized within 1ms usually, but outliers happen.

If US-EAST-1 clock is 2 seconds fast, its writes always win even if they're older. This causes lost updates. User A updates email in US-WEST-2. User A updates phone in US-EAST-1 simultaneously. Both writes succeed locally. Replication kicks in. Last-writer-wins says US-EAST-1 wins due to clock skew. Email update is lost. Phone update persists. User A's email shows old value.

Better conflict resolution: Application-level versioning. Every item has version counter. Read version, increment it, write with expected version. If version changed between read and write, retry. This detects conflicts regardless of clock skew.

Or use DynamoDB Streams to capture all writes, detect conflicts in application logic, merge values. More complex but gives full control.

Testing consistency problems is hard. In development, everything is single-region. Consistency problems don't surface. In staging, traffic is low, replication is fast, consistency windows are small. Problems are rare.

In production with global traffic, problems appear. User in Australia writes, gets routed to AP-SOUTHEAST-2. Immediately another request goes to US-WEST-2 for static content. They see inconsistent state.

How to test: Introduce artificial replication delay. Configure DynamoDB Global Tables with 5-second lag in test environment. Or simulate by reading from trailing replica intentionally. This surfaces consistency bugs before production.

Common consistency anti-patterns.

Anti-pattern one: Assuming DynamoDB is strongly consistent across regions. It's not. It's eventually consistent. Design UI and application logic for this. Show loading states. Use version numbers. Make writes sticky.

Anti-pattern two: Reading from Aurora secondary immediately after write to primary. You'll see stale data 45-85ms old. Either read from primary or accept eventual consistency and design for it.

Anti-pattern three: Not testing with replication lag. Development is fast, production is real. Introduce artificial lag in tests to surface bugs.

Anti-pattern four: Trusting last-writer-wins without understanding clock skew implications. Use application-level versioning for critical data.

Before we wrap up, pause and answer these questions.

Question one: Aurora is CP. DynamoDB is AP. What does this mean for write behavior during network partition between regions?

Question two: User updates their profile in US-EAST-1 DynamoDB. Immediately refreshes and gets routed to US-WEST-2. They see old data. Is this a bug?

Question three: You need strong consistency for order processing. Should you use Aurora or DynamoDB Global Tables?

Take a moment.

Answers.

Question one: Aurora CP: During partition, secondary regions refuse writes to maintain consistency. Primary continues accepting writes. Availability suffers but consistency guaranteed. DynamoDB AP: During partition, both regions continue accepting writes. Availability maintained but conflicts may occur. These are resolved after partition heals via last-writer-wins.

Question two: Not a bug. This is eventual consistency working as designed. DynamoDB Global Tables is AP - availability over consistency. Replication takes 1-3 seconds. If user reads before replication completes, they see old data. Fix by making writes sticky to region or showing "synchronizing" message.

Question three: Aurora. Strong consistency requires CP model. Aurora provides this via primary-secondary architecture. All order writes go to primary, transactions are ACID-compliant, reads from primary see latest data. DynamoDB eventual consistency would cause order corruption - inventory counts wrong, double charges, race conditions.

Let's recap what we covered.

First: CAP theorem forces a choice. Consistency, Availability, Partition tolerance - pick two. Multi-region requires partition tolerance, so you choose CP or AP. Aurora is CP. DynamoDB is AP.

Second: Consistency models from strong to eventual. Aurora primary provides strong consistency within region, eventual across regions. DynamoDB provides eventual consistency globally, read-your-writes if sticky to region.

Third: Eventual consistency causes user-visible bugs if not handled. Stale reads after writes, lost updates from conflicts, inconsistent UI state. Fix with sticky writes, version numbers, "saving" UI indicators.

Fourth: Aurora CP means secondary regions refuse writes during partitions. DynamoDB AP means all regions accept writes, conflicts resolved later. Choose based on use case - financial needs CP, user preferences can use AP.

Fifth: Test with artificial replication lag. Development doesn't surface consistency problems. Production does. Simulate lag in testing.

Remember Episodes 3 and 6 where we discussed Aurora and DynamoDB replication? Now you understand the consistency trade-offs. Aurora's 45-85ms lag with CP guarantees. DynamoDB's 1-3 second lag with AP trade-offs. Both are correct architectures for different use cases.

We'll revisit consistency in Episode 12 during disaster recovery. When you failover Aurora from US-EAST-1 to US-WEST-2, what happens to in-flight transactions? What consistency guarantees exist during failover? Understanding CAP helps you design failover procedures correctly.

Next time: Multi-Region Kubernetes Patterns with service mesh.

Episode 4 covered EKS multi-cluster basics. Independent clusters, no federation. But how do you actually implement cross-cluster service discovery at scale? How does Istio multi-cluster mesh work in production?

You'll learn Istio multi-primary configuration for hot-hot EKS. How Envoy sidecars route between clusters intelligently. Virtual services for traffic splitting across regions. Circuit breakers and retries for cross-region reliability. And the operational complexity cost - is service mesh worth it for your team maturity?

Because service mesh adds capability but also complexity. Let's make sure the trade-off makes sense for your architecture.

See you in Episode 11.
