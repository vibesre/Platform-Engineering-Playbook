Jordan: Welcome to part two of our four-part AWS re:Invent twenty twenty-five series. <break time="0.4s"/> In episode forty-nine, we covered agentic AI and frontier agents. Today, we're going deep on infrastructure: chips, serverless evolution, and Werner Vogels' framework for thriving in the AI era. <break time="0.6s"/> But first, let's check what else is happening in platform engineering.

Jordan: The CNCF just released their Q4 twenty twenty-five Technology Radar for AI tools in cloud native ecosystems. <break time="0.3s"/> NVIDIA Triton, Metaflow, and Model Context Protocol are leading in adoption and developer trust. But here's the interesting part. <break time="0.4s"/> The Agent2Agent protocol received a ninety-four percent recommendation score. That's developers signaling which agentic AI standards they trust for production. If you're building AI agents, these are the patterns to follow.

Jordan: And speaking of cloud native, the ecosystem just hit fifteen point six million developers. <break time="0.3s"/> That's according to CNCF and SlashData's latest survey. Seventy-seven percent of backend developers are now using at least one cloud native technology. And here's a sign of convergence: <break time="0.3s"/> forty-one percent of AI and ML developers now identify as cloud native. The silos between AI and infrastructure teams are breaking down. <break time="0.5s"/> That's exactly who AWS is targeting with their re:Invent infrastructure announcements. Let's dig in.

Alex: Let's start with silicon. <break time="0.3s"/> AWS is building its own chip empire, and Graviton five is the latest milestone.

Jordan: Why does custom silicon matter so much?

Alex: Control and differentiation. <break time="0.3s"/> When you design your own chips, you control the cost structure. You can optimize for your specific workloads. And you create features competitors can't easily replicate. <break time="0.4s"/> Here's the key stat: ninety-eight percent of AWS's top one thousand customers are already using Graviton. This isn't experimental anymore. It's mainstream infrastructure.

Jordan: What does Graviton five actually deliver?

Alex: One hundred ninety-two cores. <break time="0.3s"/> Twenty-five percent better compute performance compared to Graviton four. Thirty-three percent lower inter-core latency. And a five-times larger L3 cache. <break time="0.4s"/> It's built on Arm Neoverse V3 architecture using TSMC's three nanometer process. The new instance types, M9g, C9g, and R9g, launch in twenty twenty-six.

Jordan: What are customers actually seeing in production?

Alex: SAP reported thirty-five to sixty percent performance improvement for S/4HANA workloads. <break time="0.3s"/> Atlassian saw thirty percent higher performance with significant cost reduction. <break time="0.3s"/> Honeycomb, the observability company, measured thirty-six percent better throughput. <break time="0.4s"/> These aren't benchmarks. These are production results.

Jordan: So for platform teams, the question is whether their workloads are Graviton-ready?

Alex: Exactly. Most container workloads compile seamlessly for ARM. The migration patterns are well-established now. If you're not running Graviton, you're leaving price-performance on the table.

Jordan: <break time="0.6s"/> Let's talk about AI training economics. Trainium three is AWS's answer to GPU constraints.

Alex: The challenge is that training large models is expensive. GPU supply is still constrained. <break time="0.3s"/> AWS is offering an alternative: custom AI chips designed specifically for training workloads.

Jordan: What do the numbers look like?

Alex: Trainium three UltraServers deliver four point four times more compute performance versus Trainium two. <break time="0.3s"/> Fifty percent cost reduction for AI training. <break time="0.3s"/> Three hundred sixty-two FP8 petaflops per UltraServer with up to one hundred forty-four chips. <break time="0.3s"/> And four times better energy efficiency. <break time="0.4s"/> EC2 UltraClusters three point zero can connect thousands of UltraServers scaling up to one million chips total.

Jordan: Who's actually using this?

Alex: Anthropic is using Trainium for Claude training. <break time="0.3s"/> Metagenomi for genomics research. <break time="0.3s"/> Ricoh for document processing AI. <break time="0.3s"/> And Decart achieved four times faster inference for real-time generative video at half the cost of GPUs. <break time="0.4s"/> AWS also announced Trainium four on the roadmap, which will be NVIDIA NVLink compatible. They're playing the long game.

Jordan: And there's an on-premises option now?

Alex: AWS AI Factories. Complete Trainium-based training infrastructure for organizations with data sovereignty requirements. You can run AWS's AI compute stack in your own data center.

Jordan: <break time="0.6s"/> Now let's talk about Lambda. AWS just fundamentally changed what serverless can do.

Alex: Lambda Durable Functions. <break time="0.3s"/> The traditional Lambda timeout is fifteen minutes. Complex workflows required Step Functions. <break time="0.4s"/> Now you can build stateful workflows directly in Lambda that run from seconds to one full year.

Jordan: How does it work?

Alex: Two new primitives. <break time="0.3s"/> context dot step creates durable checkpoints. Your function can execute some code, checkpoint the result, and if anything fails, it resumes from that checkpoint. <break time="0.4s"/> context dot wait suspends execution and resumes when an event arrives. You can wait for human approval. External API callbacks. Timer expirations. All natively in Lambda.

Jordan: Can you give us an example?

Alex: Picture a data pipeline that fetches data, then waits up to seven days for human approval, then processes the data after approval. <break time="0.4s"/> In the old world, you'd build a Step Functions state machine, handle the callback pattern, manage the state store. <break time="0.3s"/> Now it's three lines of code with context dot step and context dot wait.

Jordan: What use cases does this unlock?

Alex: Human approval workflows. Long-running data pipelines. Multi-day batch processing. Event-driven orchestration. <break time="0.4s"/> If you're using Step Functions for straightforward state management, Lambda Durable might be simpler. It's not replacing Step Functions for complex orchestration, but it eliminates a lot of boilerplate.

Jordan: What else is new in Lambda?

Alex: Lambda Managed Instances gives you EC2 compute power with Lambda's simplicity. It's a bridge between serverless and traditional compute. <break time="0.3s"/> And IPv6 VPC support saves you thirty-plus dollars per month on NAT Gateway costs. That's low-hanging fruit for any VPC running Lambda.

Jordan: <break time="0.6s"/> Let's talk cost optimization. Database Savings Plans.

Alex: Up to thirty-five percent savings for serverless databases. <break time="0.3s"/> Up to twenty percent for provisioned instances. <break time="0.3s"/> One-year term commitment. Covers Aurora, RDS, DynamoDB, and more.

Jordan: How does it work in practice?

Alex: You commit to a dollar-per-hour spend. AWS automatically applies that commitment across all covered databases. It's flexible across database types. For most tiers, there's no upfront payment required.

Jordan: Platform engineering angle?

Alex: This is an easy cost optimization lever. If your database spend is stable and predictable, commit today. Stack it with Reserved Instances where applicable. <break time="0.3s"/> The ROI calculation is straightforward: stable spend equals immediate savings.

Jordan: <break time="0.6s"/> Now let's talk about Werner Vogels. His final re:Invent keynote after fourteen years.

Alex: He opened by saying, <break time="0.3s"/> quote, this is my final re:Invent keynote. I'm not leaving Amazon or anything like that, but I think that after fourteen re:Invents you guys are owed young, fresh, new voices. End quote. <break time="0.4s"/> Then he laid out a framework for thriving in the AI era.

Jordan: The Renaissance Developer.

Alex: Five qualities. <break time="0.4s"/> First: be curious. AI lowers the barrier to learning new things. You can explore any technology in hours, not months. <break time="0.4s"/> Second: think in systems. Architecture matters more than ever. AI writes code. You design systems. <break time="0.4s"/> Third: communicate precisely. AI amplifies unclear thinking. Vague prompts produce vague code. <break time="0.4s"/> Fourth: own your work. Quote, vibe coding is fine, but only if you pay close attention to what is being built. The work is yours, not that of the tools. You build it, you own it. End quote. <break time="0.4s"/> Fifth: become a polymath. Cross-disciplinary skills differentiate. Breadth plus depth equals competitive advantage.

Jordan: And he introduced a concept every platform engineer needs to understand.

Alex: Verification debt. <break time="0.4s"/> AI generates code faster than humans can comprehend it. That creates a gap between what gets written and what gets understood. <break time="0.3s"/> The gap keeps growing until something breaks in production.

Jordan: So code reviews become more important, not less.

Alex: Exactly. Vogels said, <break time="0.3s"/> quote, we all hate code reviews. It's like being a twelve-year-old and standing in front of the class. But the review becomes the control point to restore balance. End quote. <break time="0.4s"/> For AI-generated code, human review is the last line of defense.

Jordan: The big question everyone asks: will AI take my job?

Alex: Vogels' answer: <break time="0.3s"/> quote, will AI take my job? Maybe. Will AI make me obsolete? Absolutely not. <break time="0.3s"/> If you evolve. End quote.

Jordan: <break time="0.6s"/> Let's wrap with key takeaways. <break time="0.4s"/> First, Graviton five is the new default. One hundred ninety-two cores, twenty-five percent faster, and ninety-eight percent of top customers already on Graviton. The ARM migration is no longer optional.

Alex: Second, Trainium three changes AI economics. Fifty percent cost reduction for training. If you're evaluating AI infrastructure, Trainium is now a serious alternative to NVIDIA.

Jordan: Third, Lambda Durable Functions simplify orchestration. Workflows that run up to a year. No more Step Functions for straightforward state management.

Alex: Fourth, Database Savings Plans are easy wins. Thirty-five percent savings on serverless databases. If your database spend is predictable, commit today.

Jordan: Fifth, verification debt is real. Werner Vogels' warning: AI speed creates new risks. Code reviews are more important, not less.

Alex: <break time="0.5s"/> Next episode, we're diving into EKS Capabilities. AWS is now managing your Argo CD, Crossplane, and ACK controllers. Combined with one hundred thousand node clusters and natural language Kubernetes management, is this the era of invisible infrastructure?

Jordan: The infrastructure decisions you make today compound for years. <break time="0.4s"/> Choose wisely.
