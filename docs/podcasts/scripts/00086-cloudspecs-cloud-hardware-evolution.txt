Alex: Welcome to the Platform Engineering Playbook Daily Podcast. Today's news and a deep dive to help you stay ahead in platform engineering.

Jordan: Today we're diving into some uncomfortable research that challenges everything we think we know about cloud hardware. <break time="0.3s"/> A new paper from T U M reveals that the best performing cloud instance for your money was released in two thousand sixteen. And nothing since has come close. <break time="0.3s"/> This is the kind of finding that should make every platform engineer and FinOps practitioner sit up and pay attention.

Alex: Before we get into that bombshell, let's run through the news. We've got seven items covering Kubernetes development, A I tooling challenges, and a major NVIDIA announcement.

Jordan: First up, a survey from DevOps dot com shows that wider adoption of A I coding tools is creating new challenges for DevOps teams. <break time="0.3s"/> As more developers use A I assistants to generate code faster, teams are struggling with increased code review burden, security validation, and deployment frequency. <break time="0.3s"/> The velocity gains from A I are exposing bottlenecks further down the pipeline. <break time="0.3s"/> This is a real pattern we're seeing across the industry. A I helps developers write code faster, but the downstream processes haven't scaled to match. <break time="0.3s"/> Code reviews pile up, security scans take longer, and C I pipelines become the new bottleneck.

Alex: Second, last week in Kubernetes development brings some notable changes. The Kubernetes Dashboard project has been archived and is now unmaintained. If you're using it, migrate to Headlamp, which has moved to <phoneme alphabet="ipa" ph="sɪɡ">SIG</phoneme> U I. <break time="0.3s"/> Also, version one point three six release cycle starts soon, with one point three seven and one point three eight also planned for two thousand twenty-six. The release team is accepting shadow applications if you want to get involved.

Jordan: On the technical side, the Watch Cache Initialization Post Start Hook is now enabled by default in the API server. This strengthens startup guarantees and reduces race conditions that could affect watch behavior. <break time="0.3s"/> Core D N S got a security hardening release with version one point fourteen, which adds regex length limits to prevent certain denial of service attacks. <break time="0.3s"/> And Node Local C R I Socket was promoted to G A, which is useful for multi-runtime environments.

Alex: Third, a heads up for Windows administrators. <break time="0.3s"/> Windows Secure Boot U E F I certificates are expiring in June two thousand twenty-six. <break time="0.3s"/> This has been a hot topic on Reddit's sysadmin community because Microsoft's documentation isn't entirely clear on what actions are needed. <break time="0.3s"/> If you're managing Windows infrastructure, start testing certificate updates in non-production environments now. <break time="0.3s"/> Don't wait until June to find out your machines won't boot.

Jordan: Fourth, A W S Lambda now supports dot NET ten as both a managed runtime and container base image. <break time="0.3s"/> A W S will automatically apply security updates to the managed runtime, which reduces operational burden. <break time="0.3s"/> If you're running dot NET eight on Lambda, plan your upgrade path. <break time="0.3s"/> The managed runtime makes serverless dot NET much simpler to maintain long-term.

Alex: Fifth, Amazon M Q now supports certificate-based authentication with mutual T L S for Rabbit M Q brokers. <break time="0.3s"/> This lets you use X dot five oh nine client certificates for authentication instead of username and password. <break time="0.3s"/> Mutual T L S provides both encryption and client verification, which is a significant security improvement for message queue infrastructure. <break time="0.3s"/> If you're running Rabbit M Q in A W S, this is worth evaluating.

Jordan: Sixth, we have a contrarian take worth discussing. <break time="0.3s"/> A blog post titled M C P is a fad makes some pointed arguments against the Model Context Protocol that Anthropic introduced. <break time="0.3s"/> The author argues that M C P is solving an overstated problem. Frameworks like Lang Chain already abstract away tool integrations without needing separate processes.

Alex: The criticism goes deeper than that. The author points out three architectural concerns. <break time="0.3s"/> First, M C P creates an incoherent toolbox problem. When tools come from different M C P servers, they don't know about each other, and agents become less effective as tool count grows. <break time="0.3s"/> Second, each M C P server runs as a separate long-lived process, leading to dangling subprocesses, memory leaks, and resource contention. <break time="0.3s"/> Third, security. Multiple C V Es have already been filed against M C P implementations, and the specification doesn't mandate authentication.

Jordan: The author suggests alternatives like local scripts with command runners, first-party tools integrated directly into applications, or Open A P I and REST specifications. <break time="0.3s"/> Whether you agree or not, it's worth reading if you're evaluating M C P for production use. <break time="0.3s"/> The hype cycle is real, and independent criticism helps us make better decisions.

Alex: And seventh, NVIDIA announced the Rubin platform, their next generation A I supercomputer. <break time="0.3s"/> This is a six chip system that represents a significant leap in A I infrastructure. <break time="0.3s"/> The platform includes the Vera C P U with eighty-eight custom Olympus cores optimized for agentic reasoning, and the Rubin G P U with fifty petaflops of N V F P four compute and third generation Transformer Engine.

Jordan: The networking is impressive too. <break time="0.3s"/> NVLink six provides three point six terabytes per second per G P U. The full Vera Rubin NVL seventy-two rack system delivers two hundred sixty terabytes per second total bandwidth. <break time="0.3s"/> NVIDIA is claiming ten X reduction in inference token cost versus Blackwell and four X fewer G P Us needed to train mixture of experts models. <break time="0.3s"/> Rubin products ship second half of two thousand twenty-six from A W S, Google Cloud, Microsoft, and Oracle.

Alex: That's a preview of what's coming to power the next wave of A I infrastructure. <break time="0.3s"/> But let's shift to our main topic, because what we're about to discuss might fundamentally change how you think about cloud spending and instance selection.

<break time="1.5s"/>

Jordan: Alright, let's talk about Cloudspecs. <break time="0.3s"/> This is a research paper titled Cloud Hardware Evolution Through the Looking Glass, presented at C I D R two thousand twenty-six. <break time="0.3s"/> C I D R, pronounced like the drink cider, is the Conference on Innovative Data Systems Research. It's a premier venue for database and systems research.

Alex: The authors are Till Steinert, Maximilian Kuschewski, and Viktor Leis, all from the Technical University of Munich, or T U M. <break time="0.3s"/> Viktor Leis is particularly well known in the database systems community for work on query optimization and columnar databases. <break time="0.3s"/> This is serious research from a respected institution.

Jordan: Their findings are genuinely surprising. <break time="0.3s"/> They analyzed ten years of cloud hardware data from two thousand fifteen to two thousand twenty-five, focusing primarily on A W S but comparing against Azure, G C P, and on-premise hardware. <break time="0.3s"/> The key insight is that they measured performance per dollar, not just raw performance. <break time="0.3s"/> Because in cloud computing, what matters isn't peak throughput. It's economic efficiency.

Alex: Think about it this way. <break time="0.3s"/> Cloud providers love to announce new instance types with impressive numbers. <break time="0.3s"/> More cores, more memory, faster networking. <break time="0.3s"/> But if those instances cost proportionally more, you haven't actually gained anything in terms of workload economics. <break time="0.3s"/> The T U M team normalized everything by instance cost to reveal the true picture.

Jordan: They built an interactive tool called Cloudspecs that runs entirely in your browser using Duck D B Web Assembly. <break time="0.3s"/> Duck D B is an embedded analytical database, and the Web Assembly version means you can query their entire dataset with S Q L right in your browser. <break time="0.3s"/> No backend required. <break time="0.3s"/> It's live at cloudspecs dot f y i. <break time="0.3s"/> This is exactly the kind of reproducible research we need more of.

Alex: The tool includes sample queries to get you started, and you can generate visualizations of the data. <break time="0.3s"/> There's also a frozen version at the T U M GitHub page that matches the paper exactly, for academic reproducibility. <break time="0.3s"/> They used standard benchmarks like SPEC int for C P U, T P C H for analytical queries, and T P C C for transactional workloads.

Jordan: So let's walk through what they found, starting with C P U performance. <break time="0.3s"/> Over ten years, multi-core counts increased ten X. The maximum A W S instance now offers four hundred forty-eight cores. <break time="0.3s"/> That's an impressive number. <break time="0.3s"/> But raw core count doesn't tell the whole story.

Alex: When you normalize for cost, the gains are much more modest. <break time="0.3s"/> With A W S Graviton, their custom A R M-based processors, you see about three X improvement in performance per dollar over the decade. <break time="0.3s"/> Without Graviton, using Intel or A M D instances, it's closer to two X. <break time="0.3s"/> That's still improvement, but it's not the ten X you might expect from headline numbers.

Jordan: And in their database benchmarks, the story is even more conservative. <break time="0.3s"/> Using T P C H for analytical queries and T P C C for in-memory transactional workloads, they saw only two to two and a half X improvement over the decade. <break time="0.3s"/> That's roughly seven to ten percent compound annual growth in database performance per dollar.

Alex: For context, they also benchmarked on-premise A M D servers and found similarly modest gains. About one point seven X from two thousand seventeen to two thousand twenty-five. <break time="0.3s"/> So this isn't just a cloud problem or A W S prioritizing margins. It's the end of Moore's Law playing out in real infrastructure economics. <break time="0.3s"/> The easy gains from process shrinks are over.

Jordan: Memory is even more stark. <break time="0.3s"/> The T U M researchers found that D R A M capacity per dollar has, quote, effectively flatlined, end quote. <break time="0.3s"/> Memory-optimized instances from two thousand sixteen offered three point three X better value than compute-optimized instances at the time. <break time="0.3s"/> That gap has narrowed slightly, but memory remains expensive relative to compute.

Alex: In absolute terms, memory bandwidth jumped five X from D D R three to D D R five. <break time="0.3s"/> But cost-adjusted, it's only about two X improvement over the decade. <break time="0.3s"/> And here's a concerning trend. Recent A I-driven demand for D D R five has pushed prices up further, limiting even those modest gains. <break time="0.3s"/> The A I boom is creating memory scarcity that affects all workloads.

Jordan: This has real implications for application architecture. <break time="0.3s"/> In-memory databases, caching layers, and memory-intensive workloads haven't gotten proportionally cheaper to run. <break time="0.3s"/> If your cost optimization strategy assumed memory would follow the same curve as compute, you need to recalibrate.

Alex: Here's the one bright spot in the research. <break time="0.3s"/> Network performance showed genuine improvement. <break time="0.3s"/> Ten X better bandwidth per dollar over the decade. <break time="0.3s"/> In absolute terms, we went from ten gigabit to six hundred gigabit per second. That's sixty X raw improvement. <break time="0.3s"/> This is driven by A W S Nitro cards and network-optimized instance families.

Jordan: Network is the only category where cloud providers have delivered meaningful price-performance gains. <break time="0.3s"/> Which explains a lot about modern cloud architecture. <break time="0.3s"/> Disaggregated storage, microservices communicating over the network, S three as a primary data store. <break time="0.3s"/> These patterns make economic sense because network is where the efficiency gains are.

Alex: If network is cheap and fast, why attach storage locally? <break time="0.3s"/> This is the economic logic behind E B S, E F S, and S three. <break time="0.3s"/> Cloud providers have invested heavily in network because it enables their profitable storage services. <break time="0.3s"/> The incentives align.

Jordan: But that brings us to the most shocking finding in the paper. <break time="0.3s"/> N V M E storage performance. <break time="0.3s"/> The researchers found that I O throughput has been effectively unchanged since two thousand sixteen. <break time="0.3s"/> Capacity has been flat since two thousand nineteen. <break time="0.3s"/> And here's the headline that should make every platform engineer pause.

Alex: The i three instance family, launched in two thousand sixteen, still delivers the best I O performance per dollar. <break time="0.3s"/> By nearly two X. <break time="0.3s"/> Let me say that again. <break time="0.3s"/> A nine-year-old instance type beats everything A W S has released since in terms of storage price-performance.

Jordan: A W S now offers thirty-six N V M E instance families. <break time="0.3s"/> Thirty-six different options. <break time="0.3s"/> And none of them match the i three's price-performance for I O-intensive workloads. <break time="0.3s"/> This is genuinely remarkable. <break time="0.3s"/> New instance types keep coming, but they're not better values.

Alex: This is wild when you compare to on-premise hardware. <break time="0.3s"/> P C I E four and P C I E five have each doubled N V M E performance in the on-premise world. <break time="0.3s"/> So on-premise has seen roughly four X improvement while cloud has seen zero. <break time="0.3s"/> The gap between cloud and on-premise storage performance is widening, not closing.

Jordan: The Hacker News discussion of this paper surfaced some theories about why this happened. <break time="0.3s"/> Let's walk through them because they reveal important things about cloud economics.

Alex: First, there's a technical distinction that matters. <break time="0.3s"/> The i three instances use direct N V M E attachment. The physical drives are connected directly to the instance. <break time="0.3s"/> Newer families like m six i d and r six i d route N V M E through the Nitro virtualization layer. <break time="0.3s"/> Different architecture, different performance characteristics. <break time="0.3s"/> The virtualization layer adds latency and throughput constraints.

Jordan: Second, A W S may be intentionally capping N V M E performance to extend S S D lifespan. <break time="0.3s"/> Endurance is a real concern at cloud scale. <break time="0.3s"/> S S Ds have limited write cycles. <break time="0.3s"/> If customers don't actually demand maximum I O P S, why allow them to burn through expensive drives faster than necessary? <break time="0.3s"/> Throttling makes economic sense for A W S.

Alex: Third, and this is probably the biggest factor. <break time="0.3s"/> E B S is more profitable than local N V M E storage. <break time="0.3s"/> A W S has strong business incentive to push customers toward networked storage. <break time="0.3s"/> E B S has continuous revenue. <break time="0.3s"/> Local N V M E is included in instance pricing. <break time="0.3s"/> Why invest in optimizing local drives when you'd rather customers use E B S?

Jordan: And fourth, most workloads simply don't need maximum I O P S. <break time="0.3s"/> Storage-optimized instances are niche. <break time="0.3s"/> If ninety percent of customers are satisfied with virtualized N V M E performance, there's limited business case for improvement. <break time="0.3s"/> The squeaky wheel gets the grease, and most wheels aren't squeaking about local storage performance.

Alex: So what does this mean for platform engineers? <break time="0.3s"/> Let's talk through actionable implications.

Jordan: First, stop assuming newer equals better per dollar. <break time="0.3s"/> This is a mindset shift. <break time="0.3s"/> Cloud marketing tells you the latest generation is always the best choice. <break time="0.3s"/> The data says otherwise. <break time="0.3s"/> Run actual benchmarks against your workload profiles. <break time="0.3s"/> Use the Cloudspecs tool to query historical data. <break time="0.3s"/> For I O-heavy workloads, the i three might genuinely be your best choice in two thousand twenty-six.

Alex: Second, optimize for performance per dollar, not raw performance. <break time="0.3s"/> This requires a mindset shift for engineers who focus on benchmarks. <break time="0.3s"/> Your finance team already thinks this way. <break time="0.3s"/> Your capacity planning should too. <break time="0.3s"/> The Cloudspecs methodology gives you a framework for making these comparisons systematically.

Jordan: Third, leverage the network improvements. <break time="0.3s"/> Network is where cloud actually delivers value. <break time="0.3s"/> Disaggregated architectures that separate compute from storage make economic sense because network has improved ten X while local storage hasn't improved at all. <break time="0.3s"/> This is why S three and E B S dominate over local instance storage.

Alex: Fourth, reconsider repatriation for storage-heavy workloads. <break time="0.3s"/> The T U M research shows the on-premise gap is widening for N V M E. <break time="0.3s"/> If you have predictable, storage-intensive workloads with high I O requirements, the economics may have shifted in favor of on-premise or colocation. <break time="0.3s"/> This isn't universal advice, but it warrants analysis.

Jordan: Fifth, expect specialization, not uniform improvement. <break time="0.3s"/> The era of everything getting cheaper at the same rate is over. <break time="0.3s"/> Custom silicon like Graviton delivers C P U gains. <break time="0.3s"/> Nitro delivers network gains. <break time="0.3s"/> But general-purpose commodity improvements have stalled. <break time="0.3s"/> Future gains will come from hardware-software codesign and workload-specific optimization, not Moore's Law.

Alex: The Cloudspecs tool itself is worth highlighting for your workflow. <break time="0.3s"/> It runs entirely in your browser using Duck D B Web Assembly. <break time="0.3s"/> No backend required, no data leaving your machine. <break time="0.3s"/> You can write S Q L queries against their A W S instance dataset and generate visualizations. <break time="0.3s"/> There are sample queries to get you started with common analyses.

Jordan: The tool is at cloudspecs dot f y i for the latest data, and there's a frozen version at tum-dis dot github dot i o slash cloudspecs that matches the C I D R paper exactly. <break time="0.3s"/> If you're doing capacity planning, cost optimization, or instance selection, this should be in your toolkit.

Alex: One thing I appreciate about this research is the intellectual honesty. <break time="0.3s"/> The authors aren't anti-cloud. <break time="0.3s"/> They're quantifying trade-offs that cloud providers don't advertise. <break time="0.3s"/> A W S, Azure, and G C P have every incentive to launch new instance families with bigger headline numbers. <break time="0.3s"/> Marketing departments love bigger numbers. <break time="0.3s"/> But bigger numbers don't automatically mean better value.

Jordan: Viktor Leis and his team at T U M have done the community a genuine service. <break time="0.3s"/> This is independent research that helps practitioners make informed decisions. <break time="0.3s"/> It's the kind of work that should be happening more in our field. <break time="0.3s"/> If you're doing capacity planning or cost optimization, bookmark cloudspecs dot f y i.

Alex: Let's summarize the key statistics from the paper in a way you can share with your team. <break time="0.3s"/> C P U cores increased ten X over the decade, but cost-adjusted performance only two to three X. <break time="0.3s"/> Memory bandwidth increased five X, but cost-adjusted only two X. <break time="0.3s"/> Network increased sixty X raw, and ten X cost-adjusted. That's the win. <break time="0.3s"/> N V M E storage? Zero improvement in throughput. Negative improvement when you factor in that the two thousand sixteen i three is still the best value by two X.

Jordan: The practical takeaway is clear. <break time="0.3s"/> Don't blindly adopt the latest instance families because marketing says they're better. <break time="0.3s"/> Benchmark your actual workloads. <break time="0.3s"/> Consider older instance types that may offer better economics. <break time="0.3s"/> And recognize that cloud providers optimize for their margins, not your performance per dollar.

Alex: If you take one thing from this episode, let it be this. <break time="0.3s"/> Question the assumption that newer equals better in cloud computing. <break time="0.3s"/> The data shows that assumption is often wrong. <break time="0.3s"/> And nine years after launch, the i three might still be your best option for storage-intensive workloads.

Jordan: That's a great place to wrap. <break time="0.3s"/> Cloud hardware stagnation is real, and now we have rigorous academic data to prove it. <break time="0.3s"/> The paper is Cloudspecs Cloud Hardware Evolution Through the Looking Glass from C I D R two thousand twenty-six. <break time="0.3s"/> Authors Till Steinert, Maximilian Kuschewski, and Viktor Leis from the Technical University of Munich.

Alex: We've linked the paper, the interactive tool, and the GitHub repository in the show notes. <break time="0.3s"/> If you found this analysis useful, share it with your team and your FinOps practitioners. <break time="0.3s"/> These are the kinds of insights that can save real money on infrastructure spend.

Jordan: Until next time, keep questioning the defaults. <break time="0.3s"/> Newer isn't always better. <break time="0.3s"/> And sometimes the best instance for your workload is nine years old.
