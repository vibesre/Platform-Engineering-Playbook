Jordan: Today we're diving into a service mesh mystery that's challenging everything we thought we knew about performance. [pause] <phoneme alphabet="ipa" ph="ˈɪstioʊ">Istio</phoneme> Ambient reached <say-as interpret-as="characters">GA</say-as> in November twenty twenty-four with eight percent <say-as interpret-as="characters">mTLS</say-as> overhead compared to sidecar's hundred sixty-six percent. [pause] Impressive, right? [pause short] But <phoneme alphabet="ipa" ph="ˈsɪliəm">Cilium</phoneme> promised even better with kernel-level <phoneme alphabet="ipa" ph="i bi pi ɛf">eBPF</phoneme>—theoretically, processing packets directly in the kernel should beat user-space proxies every time.

Alex: And then the October twenty twenty-five academic benchmarks dropped.

Jordan: Exactly. [pause] <phoneme alphabet="ipa" ph="ˈsɪliəm">Cilium</phoneme> showed ninety-nine percent overhead. [pause] User-space beat the kernel. [pause] What happened?

Alex: So we've got this counterintuitive result that demands explanation. And the answer reveals something fundamental about architecture design—that where you draw boundaries matters more than raw execution speed.

Jordan: Let's set the stakes here. [pause short] Platform teams managing thousands of pods are paying real money for sidecars. [pause short] Two hundred fifty megabytes per pod times a thousand pods is two hundred fifty gigabytes. [pause] At <say-as interpret-as="characters">AWS</say-as> memory pricing, that's about a hundred twenty-seven thousand dollars a year just for the mesh infrastructure.

Alex: Just for the proxies, before you even count the latency penalty or engineering time managing them.

Jordan: Right. [pause] So the sidecarless revolution promised to solve this. [pause short] Two competing visions emerged—<phoneme alphabet="ipa" ph="ˈsɪliəm">Cilium</phoneme> saying "move everything to the kernel with <phoneme alphabet="ipa" ph="i bi pi ɛf">eBPF</phoneme>" and <phoneme alphabet="ipa" ph="ˈɪstioʊ">Istio</phoneme> Ambient saying "use purpose-built user-space proxies." [pause] Radically different architectures.

Alex: And choosing wrong means either you're wasting money on inefficient infrastructure, or worse, your <say-as interpret-as="characters">API</say-as> server crashes when you scale to enterprise sizes. [pause] So this matters.

Jordan: Okay, let's start with the <phoneme alphabet="ipa" ph="i bi pi ɛf">eBPF</phoneme> promise. What was <phoneme alphabet="ipa" ph="ˈsɪliəm">Cilium</phoneme> trying to achieve?

Alex: The core idea is elegant. [pause short] Traditional service meshes run <phoneme alphabet="ipa" ph="ˈɛnvɔɪ">Envoy</phoneme> proxies in user-space—every packet has to cross from the kernel into user-space for processing, then back to the kernel to continue its journey. [pause] Those context switches are expensive. [pause] <phoneme alphabet="ipa" ph="ˈsɪliəm">Cilium</phoneme> said "what if we process packets entirely in the Linux kernel using <phoneme alphabet="ipa" ph="i bi pi ɛf">eBPF</phoneme> programs?"

Jordan: So <phoneme alphabet="ipa" ph="i bi pi ɛf">eBPF</phoneme> programs are like little sandboxed programs that run directly in kernel space.

Alex: Right. [pause short] The Linux kernel has hooks at various points—when a packet arrives, when a connection is established, when data is sent. [pause] <phoneme alphabet="ipa" ph="ˈsɪliəm">Cilium</phoneme> loads <phoneme alphabet="ipa" ph="i bi pi ɛf">eBPF</phoneme> programs at these hooks to intercept traffic. [pause short] For L four processing like <say-as interpret-as="characters">TCP</say-as> connections and routing, everything happens in the kernel. [pause] Encryption uses WireGuard, which is also kernel-based. [pause] The promise was maximum efficiency—no expensive transitions between kernel and user-space for basic traffic.

Jordan: And for L seven <say-as interpret-as="characters">HTTP</say-as> traffic?

Alex: That's where <phoneme alphabet="ipa" ph="ˈsɪliəm">Cilium</phoneme> still needs <phoneme alphabet="ipa" ph="ˈɛnvɔɪ">Envoy</phoneme>. [pause short] Because <say-as interpret-as="characters">HTTP</say-as> parsing, routing rules, retries—that's complex application-layer stuff. [pause] So <phoneme alphabet="ipa" ph="ˈsɪliəm">Cilium</phoneme> deploys one shared <phoneme alphabet="ipa" ph="ˈɛnvɔɪ">Envoy</phoneme> proxy per node. [pause] When traffic needs L seven capabilities, the <phoneme alphabet="ipa" ph="i bi pi ɛf">eBPF</phoneme> programs direct it to that shared <phoneme alphabet="ipa" ph="ˈɛnvɔɪ">Envoy</phoneme> running in user-space.

Jordan: So it's not pure kernel processing.

Alex: No, it can't be. [pause] Every service mesh has to handle <say-as interpret-as="characters">HTTP</say-as> eventually for observability, advanced routing, retry logic. [pause] The question is where that boundary sits.

Jordan: And <phoneme alphabet="ipa" ph="ˈɪstioʊ">Istio</phoneme> Ambient took a completely different approach.

Alex: Yes. [pause short] Ambient uses ztunnel—z-tunnel, like zero-trust tunnel. [pause] It's a lightweight proxy that runs per-node in user-space. [pause short] Not in the kernel. [pause] It handles L four traffic—<say-as interpret-as="characters">TCP</say-as> connections, <say-as interpret-as="characters">mTLS</say-as> encryption, identity-based authentication, basic network policies. [pause] Crucially, ztunnel doesn't parse <say-as interpret-as="characters">HTTP</say-as> at all. [pause] It just treats traffic as opaque <say-as interpret-as="characters">TCP</say-as> streams.

Jordan: So it's doing <say-as interpret-as="characters">mTLS</say-as> handshake and encryption without looking inside to see if it's <say-as interpret-as="characters">HTTP</say-as>.

Alex: Exactly. [pause] And when you need L seven capabilities—<say-as interpret-as="characters">HTTP</say-as> routing, traffic splitting, circuit breakers—you deploy optional waypoint proxies. [pause] These are full <phoneme alphabet="ipa" ph="ˈɛnvɔɪ">Envoy</phoneme> instances, but they're deployed per service account, not per pod. [pause] So if you have a thousand pods across fifty services, you might deploy fifty waypoint proxies instead of a thousand sidecars.

Jordan: Okay, so we've got <phoneme alphabet="ipa" ph="ˈsɪliəm">Cilium</phoneme> with kernel <phoneme alphabet="ipa" ph="i bi pi ɛf">eBPF</phoneme> plus shared <phoneme alphabet="ipa" ph="ˈɛnvɔɪ">Envoy</phoneme> per node, and Ambient with user-space ztunnel plus optional waypoint proxies per service. [pause] Now let's talk about the benchmarks. What did the academic study actually measure?

Alex: The ArXiv study from October twenty twenty-five was peer-reviewed research from multiple universities. [pause] They tested four implementations—<phoneme alphabet="ipa" ph="ˈɪstioʊ">Istio</phoneme> traditional sidecar, <phoneme alphabet="ipa" ph="ˈɪstioʊ">Istio</phoneme> Ambient, <phoneme alphabet="ipa" ph="ˈsɪliəm">Cilium</phoneme>, and Linkerd—under production-realistic conditions using Fortio load generator at three thousand two hundred requests per second with two hundred millisecond backend delay simulating database calls.

Jordan: And the <say-as interpret-as="characters">mTLS</say-as> overhead results?

Alex: At p ninety-nine latency, <phoneme alphabet="ipa" ph="ˈɪstioʊ">Istio</phoneme> sidecar added a hundred sixty-six percent overhead. [pause] Linkerd added thirty-three percent. [pause] <phoneme alphabet="ipa" ph="ˈɪstioʊ">Istio</phoneme> Ambient added eight percent. [pause] And <phoneme alphabet="ipa" ph="ˈsɪliəm">Cilium</phoneme> added ninety-nine percent.

Jordan: Wait, so Ambient—running in user-space—had eight percent overhead, while <phoneme alphabet="ipa" ph="ˈsɪliəm">Cilium</phoneme>—running in the kernel—had ninety-nine percent. [pause] That's twelve times worse despite theoretically being faster.

Alex: Right. [pause] And if you look at <say-as interpret-as="characters">CPU</say-as> consumption, <phoneme alphabet="ipa" ph="ˈsɪliəm">Cilium</phoneme> used point one two cores versus Ambient's point two three cores. [pause] So <phoneme alphabet="ipa" ph="ˈsɪliəm">Cilium</phoneme> was using less <say-as interpret-as="characters">CPU</say-as> but delivering worse latency. [pause] The bottleneck wasn't raw processing power.

Jordan: So what's going on? [pause] Why does kernel-level processing underperform user-space here?

Alex: The answer is the L seven processing boundary. [pause] Remember, every service mesh has to handle <say-as interpret-as="characters">HTTP</say-as> eventually. [pause] For <phoneme alphabet="ipa" ph="ˈsɪliəm">Cilium</phoneme>, here's what happens. [pause short] A packet arrives, the <phoneme alphabet="ipa" ph="i bi pi ɛf">eBPF</phoneme> program in the kernel processes it, encrypts it with WireGuard. [pause short] Great, all in kernel space. [pause] But then, if you have any network policy that requires looking at <say-as interpret-as="characters">HTTP</say-as> headers, or you want retry logic, or you need observability metrics—that packet has to be copied from kernel memory into user-space memory so the shared <phoneme alphabet="ipa" ph="ˈɛnvɔɪ">Envoy</phoneme> proxy can parse the <say-as interpret-as="characters">HTTP</say-as>.

Jordan: So even though the initial processing is fast, you pay the cost of that kernel-to-user-space transition.

Alex: And then after <phoneme alphabet="ipa" ph="ˈɛnvɔɪ">Envoy</phoneme> processes it, the packet goes back to the kernel to continue its journey. [pause] So you're doing these expensive memory copies and context switches. [pause] The academic study found that when they disabled <say-as interpret-as="characters">HTTP</say-as> parsing entirely in <phoneme alphabet="ipa" ph="ˈsɪliəm">Cilium</phoneme>'s <phoneme alphabet="ipa" ph="ˈɛnvɔɪ">Envoy</phoneme>, throughput improved almost five times. [pause] The <phoneme alphabet="ipa" ph="i bi pi ɛf">eBPF</phoneme> part was fast—it was the transitions to handle L seven that killed performance.

Jordan: And Ambient avoids this how?

Alex: Ambient's ztunnel is purpose-built for L four. [pause] It doesn't try to parse <say-as interpret-as="characters">HTTP</say-as> at all. [pause short] When it sees a <say-as interpret-as="characters">TCP</say-as> connection, it does the <say-as interpret-as="characters">mTLS</say-as> handshake, encrypts the stream, and forwards it. [pause] Because it's not looking inside the <say-as interpret-as="characters">HTTP</say-as>, it can optimize that path aggressively—eight percent overhead means the encryption overhead is minimal. [pause] When you do need L seven processing, the traffic goes directly to a waypoint proxy that's already in user-space. [pause] No kernel transitions required.

Jordan: So Ambient accepted that L seven happens in user-space and designed around it, while <phoneme alphabet="ipa" ph="ˈsɪliəm">Cilium</phoneme> tried to stay in the kernel as long as possible but got penalized whenever L seven was needed.

Alex: Right. [pause] And for most production workloads, you're going to need some L seven capabilities. [pause short] Routing, observability, retries—these are table stakes. [pause] So <phoneme alphabet="ipa" ph="ˈsɪliəm">Cilium</phoneme>'s architecture hits the worst case more often.

Jordan: Okay, but that's just latency and <say-as interpret-as="characters">CPU</say-as>. [pause] <phoneme alphabet="ipa" ph="ˈɪstioʊ">Istio</phoneme> also published large-scale stability testing. [pause] What did that show?

Alex: This is where it gets really interesting. [pause] <phoneme alphabet="ipa" ph="ˈɪstioʊ">Istio</phoneme> set up an <phoneme alphabet="ipa" ph="ˈæʒɚ">Azure</phoneme> <phoneme alphabet="ipa" ph="ˌkubɚˈnɛtɪs">Kubernetes</phoneme> Service cluster with a thousand nodes, eleven thousand <say-as interpret-as="characters">CPU</say-as> cores, fifty thousand pods running five hundred different microservices with a hundred replicas each.

Jordan: That's enormous.

Alex: Yeah, way beyond most production deployments, which is the point—stress test at the extremes. [pause] And they simulated production churn. [pause short] Replicas scaling up and down every second, namespaces getting relabeled every minute, constant service discovery updates. [pause] Both Ambient and <phoneme alphabet="ipa" ph="ˈsɪliəm">Cilium</phoneme> were tested under these conditions.

Jordan: And?

Alex: Throughput-wise, Ambient delivered twenty-one seventy-eight queries per core versus <phoneme alphabet="ipa" ph="ˈsɪliəm">Cilium</phoneme>'s eighteen fifteen. [pause] That's a twenty percent per-core efficiency advantage, which translates to fifty-six percent more total cluster throughput when you multiply across eleven thousand cores.

Jordan: So Ambient was faster at scale.

Alex: But the bigger discovery was stability. [pause] <phoneme alphabet="ipa" ph="ˈsɪliəm">Cilium</phoneme>'s distributed control plane architecture—where every node runs a <phoneme alphabet="ipa" ph="ˈsɪliəm">Cilium</phoneme> agent that independently talks to the <phoneme alphabet="ipa" ph="ˌkubɚˈnɛtɪs">Kubernetes</phoneme> <say-as interpret-as="characters">API</say-as> server—caused the <say-as interpret-as="characters">API</say-as> server to crash under that aggressive churn.

Jordan: The <say-as interpret-as="characters">API</say-as> server crashed?

Alex: Yes. [pause] A thousand <phoneme alphabet="ipa" ph="ˈsɪliəm">Cilium</phoneme> agents all independently querying for service updates, pod labels, namespace changes—the aggregated load became unbearable. [pause] The cluster became unresponsive. [pause] <phoneme alphabet="ipa" ph="ˈɪstioʊ">Istio</phoneme>'s centralized control plane, where a single istiod manages all the ztunnels, handled the same workload without instability.

Jordan: So kernel efficiency doesn't matter if you can't stay online.

Alex: Exactly. [pause] And this reveals something important. [pause] <phoneme alphabet="ipa" ph="ˈsɪliəm">Cilium</phoneme>'s architecture makes sense at smaller scales. [pause short] Under five hundred nodes, under five thousand pods, the distributed control plane isn't a problem. [pause] But if you're planning for enterprise scale, that centralized control plane design becomes critical.

Jordan: Okay, so we've got the mystery solved. [pause] Architecture boundaries matter more than execution location. [pause] Now the practical question—when should you use each?

Alex: Let's build a decision framework. [pause short] Start with cluster size. [pause] If you're running a thousand to five thousand nodes and you need proven fifty-thousand-pod stability, <phoneme alphabet="ipa" ph="ˈɪstioʊ">Istio</phoneme> Ambient has the data. [pause] If you're under five hundred nodes, <phoneme alphabet="ipa" ph="ˈsɪliəm">Cilium</phoneme>'s <say-as interpret-as="characters">API</say-as> server issues are unlikely to surface.

Jordan: What about traffic patterns?

Alex: This is huge. [pause] If seventy percent or more of your inter-service traffic is L four—<phoneme alphabet="ipa" ph="dʒi ɑr pi si">gRPC</phoneme>, database connections, message queues—and only thirty percent needs L seven routing, Ambient wins because you deploy ztunnel for L four and add waypoint proxies only for the services that need <say-as interpret-as="characters">HTTP</say-as> capabilities. [pause] But if your traffic is pure L three slash L four with no complex <say-as interpret-as="characters">HTTP</say-as> routing at all, <phoneme alphabet="ipa" ph="ˈsɪliəm">Cilium</phoneme> can be more efficient because you're not paying for L seven infrastructure you don't use.

Jordan: Give me a concrete example.

Alex: Okay, e-commerce platform with two thousand microservices. [pause short] Eighty percent of traffic is internal <phoneme alphabet="ipa" ph="dʒi ɑr pi si">gRPC</phoneme> between backend services—inventory, pricing, recommendations. [pause short] Twenty percent is user-facing <say-as interpret-as="characters">REST</say-as> <say-as interpret-as="characters">API</say-as>s with sophisticated routing, retries, circuit breakers. [pause] With sidecars, you're deploying two thousand <phoneme alphabet="ipa" ph="ˈɛnvɔɪ">Envoy</phoneme> proxies, consuming five hundred gigabytes of memory, costing about two hundred thousand dollars a year.

Jordan: And with Ambient?

Alex: Deploy ztunnel on every node—say fifty nodes, that's fifty times twenty-six megabytes, about one point three gigs for the L four layer. [pause] Then deploy waypoint proxies for the four hundred services that need L seven—that's four hundred times a hundred megabytes, forty gigs. [pause] Total memory footprint is forty-one gigabytes instead of five hundred. [pause] You've saved a hundred eighty-six thousand dollars a year in infrastructure costs alone.

Jordan: That's a compelling business case. [pause] What about <phoneme alphabet="ipa" ph="ˈsɪliəm">Cilium</phoneme>?

Alex: <phoneme alphabet="ipa" ph="ˈsɪliəm">Cilium</phoneme> makes sense for smaller scale with pure L four requirements. [pause short] Startup with a fifty-node cluster, backend services communicating via <phoneme alphabet="ipa" ph="dʒi ɑr pi si">gRPC</phoneme>, no complex <say-as interpret-as="characters">HTTP</say-as> routing. [pause] If you're already using <phoneme alphabet="ipa" ph="ˈsɪliəm">Cilium</phoneme> for your <say-as interpret-as="characters">CNI</say-as>—the container network interface—adding service mesh features is incremental. [pause] <phoneme alphabet="ipa" ph="ˈsɪliəm">Cilium</phoneme>'s ninety-five megabytes per node is the smallest footprint you can get. [pause short] Fifty nodes times ninety-five megabytes is four point seven gigs total.

Jordan: Much cheaper than Ambient's forty-one gigs in that e-commerce example.

Alex: Right, but remember, the e-commerce platform has sophisticated L seven requirements. [pause] If the startup tries to scale to two thousand pods and adds <say-as interpret-as="characters">HTTP</say-as> routing, they'll start hitting the shared <phoneme alphabet="ipa" ph="ˈɛnvɔɪ">Envoy</phoneme> bottleneck—one proxy per node handling all L seven traffic from multiple pods. [pause] Ambient's per-service waypoints scale better at that point.

Jordan: And when should you just keep sidecars despite the cost?

Alex: Three scenarios. [pause short] One, multi-cluster federation. [pause short] If you're running services across multiple <phoneme alphabet="ipa" ph="ˌkubɚˈnɛtɪs">Kubernetes</phoneme> clusters in different regions or clouds, Ambient's multi-cluster support isn't mature yet. [pause short] Sidecars are the proven option. [pause] Two, maximum isolation for compliance. [pause short] <say-as interpret-as="characters">PCI</say-as>-<say-as interpret-as="characters">DSS</say-as>, <say-as interpret-as="characters">HIPAA</say-as>, FedRAMP—if your compliance framework requires per-workload security boundaries, sidecars give you a dedicated proxy per pod. [pause] Three, heavy L seven traffic per pod. [pause short] If every single pod is generating significant <say-as interpret-as="characters">HTTP</say-as> traffic requiring per-pod routing and retries, sidecars scale naturally because the proxy scales with the pod count.

Jordan: So it's not that sidecars are obsolete.

Alex: Not at all. [pause] They're the most mature option—seven years in production, extensive tooling, multiple vendor support options. [pause] If you're in financial services with multi-region deployment and strict compliance, the two hundred thousand dollar sidecar cost might be justified by the maturity and isolation.

Jordan: Okay, so let's say a team decides Ambient makes sense. [pause] What does migration actually look like?

Alex: Here's the reality check everyone misses. [pause] The technical migration is trivial—you can swap Ambient for sidecars in minutes. [pause short] Remove the sidecar injection label from a namespace, add the Ambient label, and <phoneme alphabet="ipa" ph="ˈɪstioʊ">Istio</phoneme> handles the transition. [pause] The organizational change is what takes ninety days.

Jordan: What does that involve?

Alex: You've got to update <say-as interpret-as="characters">CI</say-as>/<say-as interpret-as="characters">CD</say-as> pipelines for every project. [pause short] GitHub Actions workflows, GitLab <say-as interpret-as="characters">CI</say-as> configs, Jenkins files—anywhere you reference <phoneme alphabet="ipa" ph="ˈɪstioʊ">Istio</phoneme> configuration. [pause short] Documentation needs updating. [pause short] Team training—developers need to understand the new model, how ztunnel works, when to deploy waypoints. [pause] And you need gradual rollout. [pause short] Start with five to ten low-risk dev services, validate for two weeks, expand to production incrementally.

Jordan: So it's the same pattern we saw with the Fidelity OpenTofu migration—technically simple, organizationally complex.

Alex: Exactly. [pause] Fidelity migrated seventy percent of their fifty thousand state files in six months, and they said the technical side was trivial. [pause short] It was the change management that mattered. [pause] Same here. [pause short] Budget ninety days to hit thirty to fifty percent adoption if you're aggressive, longer if you want to be conservative.

Jordan: And what's the cost-benefit on that ninety-day migration effort?

Alex: If you're saving a hundred eighty-six thousand a year on infrastructure and you allocate one senior platform engineer for three months at, say, a hundred fifty thousand dollar annual salary, that's about thirty-seven thousand dollars in labor cost. [pause short] Plus maybe ten thousand for vendor support from Solo dot i-o or Tetrate. [pause] You're still saving a hundred thirty-nine thousand net in year one, and the full hundred eighty-six thousand every year after. [pause] That's a pretty clear <say-as interpret-as="characters">ROI</say-as>.

Jordan: Okay, so let's bring this home. [pause] What's the key insight here for platform engineers evaluating service meshes in twenty twenty-five?

Alex: The counterintuitive lesson is that execution location—kernel versus user-space—matters less than architecture boundaries. [pause] <phoneme alphabet="ipa" ph="ˈɪstioʊ">Istio</phoneme> Ambient wins not because user-space is inherently faster, but because it's designed around the reality that L seven processing happens in user-space anyway. [pause] <phoneme alphabet="ipa" ph="ˈsɪliəm">Cilium</phoneme>'s kernel-level <phoneme alphabet="ipa" ph="i bi pi ɛf">eBPF</phoneme> is brilliant for L four, but the architecture pays a penalty every time you need <say-as interpret-as="characters">HTTP</say-as> capabilities.

Jordan: And scale matters differently than people think.

Alex: Yes. [pause] <phoneme alphabet="ipa" ph="ˈsɪliəm">Cilium</phoneme>'s distributed control plane is a feature at small scale—resilience, no single point of failure. [pause] But at enterprise scale with aggressive churn, it becomes a liability. [pause] The <say-as interpret-as="characters">API</say-as> server can't handle a thousand independent agents. [pause] <phoneme alphabet="ipa" ph="ˈɪstioʊ">Istio</phoneme>'s centralized control plane flips that—potential single point of failure at small scale, but proven stability at fifty thousand pods.

Jordan: So the decision framework is cluster size, traffic patterns L four versus L seven, and your scale ambitions.

Alex: Right. [pause] Under five hundred nodes with pure L four, <phoneme alphabet="ipa" ph="ˈsɪliəm">Cilium</phoneme> wins on efficiency. [pause] Thousand to five thousand nodes with mixed L four and L seven, Ambient wins on cost and stability. [pause] Mission-critical multi-cluster with heavy compliance, sidecars win on maturity despite the cost. [pause] There's no universal answer—it depends on your specific constraints.

Jordan: And the migration timeline is ninety days of organizational change, not a weekend technical swap.

Alex: Correct. [pause] The technology is ready. [pause short] <phoneme alphabet="ipa" ph="ˈɪstioʊ">Istio</phoneme> Ambient reached <say-as interpret-as="characters">GA</say-as> in November twenty twenty-four after twenty-six months of development involving Google, Microsoft, and Red Hat. [pause] <phoneme alphabet="ipa" ph="ˈsɪliəm">Cilium</phoneme>'s been stable for years. [pause] The challenge is coordinating team training, <say-as interpret-as="characters">CI</say-as>/<say-as interpret-as="characters">CD</say-as> updates, and gradual rollout across your organization.

Jordan: So platform teams need to do the math on their specific situation. [pause short] Calculate your current sidecar memory cost, evaluate your traffic patterns, consider your scale trajectory, and decide whether the architecture fits your use case.

Alex: And recognize that this isn't a binary decision. [pause] You can run Ambient for cost-sensitive services, sidecars for mission-critical multi-cluster workloads, and <phoneme alphabet="ipa" ph="ˈsɪliəm">Cilium</phoneme> for small-scale L four-only clusters. [pause] Mix and match based on requirements.

Jordan: The architecture you choose matters less than choosing deliberately based on your constraints. [pause] Which I guess is the meta-lesson here—don't assume kernel is always faster, don't assume user-space is always slower. [pause] Understand the boundaries, test at your scale, and make the decision that fits your reality.

Alex: And if you want the full technical breakdown, we've got a deep-dive blog post with all the benchmark data, cost calculations, and migration playbooks. [pause short] Link in the show notes.

Jordan: The sidecarless revolution is here, but it's not about one architecture beating the other. [pause] It's about matching the architecture to the workload. [pause] That's the real engineering. [pause long]